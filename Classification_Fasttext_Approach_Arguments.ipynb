{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length: 1017 abstracts\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>sentences</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>doi: 10.1016/j.jhep.2017.02.014</td>\n",
       "      <td>[Impaired hepatic lipid synthesis from polyuns...</td>\n",
       "      <td>[NEITHER, NEITHER, NEITHER, NEITHER, NEITHER, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>doi: 10.1029/2019ms001628</td>\n",
       "      <td>[Ensembles of Global Climate Model Variants De...</td>\n",
       "      <td>[NEITHER, NEITHER, NEITHER, NEITHER, NEITHER, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>doi: 10.1002/anie.201610837</td>\n",
       "      <td>[Miller-Urey Spark-Discharge Experiments in th...</td>\n",
       "      <td>[NEITHER, NEITHER, NEITHER, EVIDENCE, NEITHER,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>doi: 10.15252/emmm.201707809</td>\n",
       "      <td>[18\\n            F‐AV‐1451 and CSF T‐tau and P...</td>\n",
       "      <td>[NEITHER, NEITHER, NEITHER, NEITHER, NEITHER, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>doi: 10.1016/j.freeradbiomed.2019.04.027</td>\n",
       "      <td>[Computational solutions in redox lipidomics –...</td>\n",
       "      <td>[NEITHER, NEITHER, NEITHER, NEITHER, NEITHER, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     document  \\\n",
       "218           doi: 10.1016/j.jhep.2017.02.014   \n",
       "369                 doi: 10.1029/2019ms001628   \n",
       "25                doi: 10.1002/anie.201610837   \n",
       "868              doi: 10.15252/emmm.201707809   \n",
       "190  doi: 10.1016/j.freeradbiomed.2019.04.027   \n",
       "\n",
       "                                             sentences  \\\n",
       "218  [Impaired hepatic lipid synthesis from polyuns...   \n",
       "369  [Ensembles of Global Climate Model Variants De...   \n",
       "25   [Miller-Urey Spark-Discharge Experiments in th...   \n",
       "868  [18\\n            F‐AV‐1451 and CSF T‐tau and P...   \n",
       "190  [Computational solutions in redox lipidomics –...   \n",
       "\n",
       "                                                labels  \n",
       "218  [NEITHER, NEITHER, NEITHER, NEITHER, NEITHER, ...  \n",
       "369  [NEITHER, NEITHER, NEITHER, NEITHER, NEITHER, ...  \n",
       "25   [NEITHER, NEITHER, NEITHER, EVIDENCE, NEITHER,...  \n",
       "868  [NEITHER, NEITHER, NEITHER, NEITHER, NEITHER, ...  \n",
       "190  [NEITHER, NEITHER, NEITHER, NEITHER, NEITHER, ...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CODE FOR LOADING THE DATASET \"dataset_aueb_argument_v3.json\"\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "label2id = {\n",
    "    'NONE': 0,\n",
    "    'EVIDENCE': 1,\n",
    "    'CLAIM': 2}\n",
    "\n",
    "def load_corpus(path, label_mapping=None):\n",
    "    with open(path) as fp:\n",
    "        corpus = json.load(fp)\n",
    "\n",
    "    documents, texts, labels = [], [], []\n",
    "    for abstract in corpus:\n",
    "        documents.append(abstract)\n",
    "        texts.append(corpus[abstract]['sentences'])\n",
    "        if isinstance(label_mapping, dict):\n",
    "            labels.append(\n",
    "                [label_mapping[str(l).upper()]\n",
    "                    for l in corpus[abstract]['labels']])\n",
    "        else:\n",
    "            labels.append([str(l).upper() for l in corpus[abstract]['labels']])\n",
    "\n",
    "    assert len(texts) == len(labels)\n",
    "    data = pd.DataFrame(\n",
    "        zip(documents, texts, labels),\n",
    "        columns=['document', 'sentences', 'labels'])\n",
    "\n",
    "    return data\n",
    "\n",
    "data = load_corpus('dataset_aueb_argument_v3.json') #, label_mapping=label2id)\n",
    "print(f'Dataset length: {len(data)} abstracts')\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length: 1669 abstracts\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>sentences</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>LMN_G5B1_10.1016_j.jenvman.2015.11.043.txt</td>\n",
       "      <td>[Title: National climate policies across Europ...</td>\n",
       "      <td>[NONE, NONE, NONE, NONE, NONE, NONE, NONE, EVI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>ABC_G1B2_10.1016_j.scs.2018.12.041.txt</td>\n",
       "      <td>[A GIS-based model to assess electric energy c...</td>\n",
       "      <td>[NONE, NONE, CLAIM, NONE, NONE, EVIDENCE, EVID...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>FGP_G3B3_PMID31021567.txt</td>\n",
       "      <td>[Title: A qualitative study on the oral health...</td>\n",
       "      <td>[NONE, NONE, NONE, NONE, NONE, NONE, NONE, NON...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1362</th>\n",
       "      <td>16476841</td>\n",
       "      <td>[Early intervention with epoetin alfa during p...</td>\n",
       "      <td>[NONE, NONE, NONE, NONE, EVIDENCE, EVIDENCE, E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1651</th>\n",
       "      <td>11148810</td>\n",
       "      <td>[Long-term effects of timolol therapy in ocula...</td>\n",
       "      <td>[NONE, CLAIM, NONE, NONE, NONE, NONE, NONE, EV...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        document  \\\n",
       "706   LMN_G5B1_10.1016_j.jenvman.2015.11.043.txt   \n",
       "649       ABC_G1B2_10.1016_j.scs.2018.12.041.txt   \n",
       "294                    FGP_G3B3_PMID31021567.txt   \n",
       "1362                                    16476841   \n",
       "1651                                    11148810   \n",
       "\n",
       "                                              sentences  \\\n",
       "706   [Title: National climate policies across Europ...   \n",
       "649   [A GIS-based model to assess electric energy c...   \n",
       "294   [Title: A qualitative study on the oral health...   \n",
       "1362  [Early intervention with epoetin alfa during p...   \n",
       "1651  [Long-term effects of timolol therapy in ocula...   \n",
       "\n",
       "                                                 labels  \n",
       "706   [NONE, NONE, NONE, NONE, NONE, NONE, NONE, EVI...  \n",
       "649   [NONE, NONE, CLAIM, NONE, NONE, EVIDENCE, EVID...  \n",
       "294   [NONE, NONE, NONE, NONE, NONE, NONE, NONE, NON...  \n",
       "1362  [NONE, NONE, NONE, NONE, EVIDENCE, EVIDENCE, E...  \n",
       "1651  [NONE, CLAIM, NONE, NONE, NONE, NONE, NONE, EV...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CODE FOR LOADING THE DATASET \"dataset.json\"\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "label2id = {\n",
    "    'NONE': 0,\n",
    "    'EVIDENCE': 1,\n",
    "    'CLAIM': 2}\n",
    "\n",
    "def load_corpus(path, label_mapping=None):\n",
    "    with open(path) as fp:\n",
    "        corpus = json.load(fp)\n",
    "\n",
    "    documents, texts, labels = [], [], []\n",
    "    for abstract in corpus:\n",
    "        documents.append(abstract)\n",
    "        texts.append(corpus[abstract]['sentences'])\n",
    "        if isinstance(label_mapping, dict):\n",
    "            labels.append(\n",
    "                [label_mapping[str(l).upper()]\n",
    "                    for l in corpus[abstract]['labels']])\n",
    "        else:\n",
    "            labels.append([str(l).upper() for l in corpus[abstract]['labels']])\n",
    "\n",
    "    assert len(texts) == len(labels)\n",
    "    data = pd.DataFrame(\n",
    "        zip(documents, texts, labels),\n",
    "        columns=['document', 'sentences', 'labels'])\n",
    "\n",
    "    return data\n",
    "\n",
    "data2 = load_corpus('dataset.json') #, label_mapping=label2id)\n",
    "print(f'Dataset length: {len(data2)} abstracts')\n",
    "data2.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate the 2 datasets\n",
    "data_final = pd.concat([data,data2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting in train-validation-test sets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Concordance Between Different Amyloid Immunoas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Importance Visual assessment of amyloid positr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Several immunoassays have been developed to me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>The agreement between CSF Aβ42 measures from d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Objective To determine the concordance between...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31999</th>\n",
       "      <td>2685</td>\n",
       "      <td>No statistically significant difference in con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32000</th>\n",
       "      <td>2685</td>\n",
       "      <td>Latanoprost 0.005% once daily reduced IOP more...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32001</th>\n",
       "      <td>2685</td>\n",
       "      <td>Latanoprost had no statistically or clinically...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32002</th>\n",
       "      <td>2685</td>\n",
       "      <td>There was no difference in hyperemia between t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32003</th>\n",
       "      <td>2685</td>\n",
       "      <td>Both concentrations of latanoprost reduced IOP...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32004 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       doc_id                                           sentence\n",
       "0           0  Concordance Between Different Amyloid Immunoas...\n",
       "1           0  Importance Visual assessment of amyloid positr...\n",
       "2           0  Several immunoassays have been developed to me...\n",
       "3           0  The agreement between CSF Aβ42 measures from d...\n",
       "4           0  Objective To determine the concordance between...\n",
       "...       ...                                                ...\n",
       "31999    2685  No statistically significant difference in con...\n",
       "32000    2685  Latanoprost 0.005% once daily reduced IOP more...\n",
       "32001    2685  Latanoprost had no statistically or clinically...\n",
       "32002    2685  There was no difference in hyperemia between t...\n",
       "32003    2685  Both concentrations of latanoprost reduced IOP...\n",
       "\n",
       "[32004 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Explode to sentences\n",
    "sentences = data_final['sentences'].explode().reset_index().rename(\n",
    "    columns={'index': 'doc_id', 'sentences': 'sentence'})\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NEITHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>NEITHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>NEITHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>NEITHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>NEITHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31999</th>\n",
       "      <td>2685</td>\n",
       "      <td>EVIDENCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32000</th>\n",
       "      <td>2685</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32001</th>\n",
       "      <td>2685</td>\n",
       "      <td>CLAIM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32002</th>\n",
       "      <td>2685</td>\n",
       "      <td>CLAIM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32003</th>\n",
       "      <td>2685</td>\n",
       "      <td>CLAIM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32004 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       doc_id     label\n",
       "0           0   NEITHER\n",
       "1           0   NEITHER\n",
       "2           0   NEITHER\n",
       "3           0   NEITHER\n",
       "4           0   NEITHER\n",
       "...       ...       ...\n",
       "31999    2685  EVIDENCE\n",
       "32000    2685      NONE\n",
       "32001    2685     CLAIM\n",
       "32002    2685     CLAIM\n",
       "32003    2685     CLAIM\n",
       "\n",
       "[32004 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Explode to the corresponding labels\n",
    "labels = data_final['labels'].explode().reset_index().rename(\n",
    "    columns={'index': 'doc_id', 'labels': 'label'})\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we drop the doc_id column as it is not needed\n",
    "labels = labels.drop(['doc_id'],axis =1)\n",
    "sentences = sentences.drop(['doc_id'],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we concatenate the 2 data frames into one\n",
    "df = pd.concat([sentences,labels], axis =1, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Concordance Between Different Amyloid Immunoas...</td>\n",
       "      <td>NEITHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Importance Visual assessment of amyloid positr...</td>\n",
       "      <td>NEITHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Several immunoassays have been developed to me...</td>\n",
       "      <td>NEITHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The agreement between CSF Aβ42 measures from d...</td>\n",
       "      <td>NEITHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Objective To determine the concordance between...</td>\n",
       "      <td>NEITHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31999</th>\n",
       "      <td>No statistically significant difference in con...</td>\n",
       "      <td>EVIDENCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32000</th>\n",
       "      <td>Latanoprost 0.005% once daily reduced IOP more...</td>\n",
       "      <td>NEITHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32001</th>\n",
       "      <td>Latanoprost had no statistically or clinically...</td>\n",
       "      <td>CLAIM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32002</th>\n",
       "      <td>There was no difference in hyperemia between t...</td>\n",
       "      <td>CLAIM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32003</th>\n",
       "      <td>Both concentrations of latanoprost reduced IOP...</td>\n",
       "      <td>CLAIM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32004 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence     label\n",
       "0      Concordance Between Different Amyloid Immunoas...   NEITHER\n",
       "1      Importance Visual assessment of amyloid positr...   NEITHER\n",
       "2      Several immunoassays have been developed to me...   NEITHER\n",
       "3      The agreement between CSF Aβ42 measures from d...   NEITHER\n",
       "4      Objective To determine the concordance between...   NEITHER\n",
       "...                                                  ...       ...\n",
       "31999  No statistically significant difference in con...  EVIDENCE\n",
       "32000  Latanoprost 0.005% once daily reduced IOP more...   NEITHER\n",
       "32001  Latanoprost had no statistically or clinically...     CLAIM\n",
       "32002  There was no difference in hyperemia between t...     CLAIM\n",
       "32003  Both concentrations of latanoprost reduced IOP...     CLAIM\n",
       "\n",
       "[32004 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we replace the \"NONE\" label with \"NEITHER\" in order to make the 2 data sets match.\n",
    "df['label'] = df['label'].replace('NONE','NEITHER')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing some very basic tokenization to extract STOPWORDS and COMMONWORDS from the train-validation data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>concordance between different amyloid immunoas...</td>\n",
       "      <td>NEITHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>importance visual assessment of amyloid positr...</td>\n",
       "      <td>NEITHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>several immunoassays have been developed to me...</td>\n",
       "      <td>NEITHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the agreement between csf aβ42 measures from d...</td>\n",
       "      <td>NEITHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>objective to determine the concordance between...</td>\n",
       "      <td>NEITHER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence    label\n",
       "0  concordance between different amyloid immunoas...  NEITHER\n",
       "1  importance visual assessment of amyloid positr...  NEITHER\n",
       "2  several immunoassays have been developed to me...  NEITHER\n",
       "3  the agreement between csf aβ42 measures from d...  NEITHER\n",
       "4  objective to determine the concordance between...  NEITHER"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting all sentences to lowercase and replacing the \".\" with \" \"\n",
    "#removing ' ' at the beginning or the end of each sentence\n",
    "df['sentence'] = df['sentence'].str.lower().str.replace('.', ' ', regex=False).str.strip()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concordance between different amyloid immunoassays and visual amyloid positron emission tomographic assessment importance visual assessment of amyloid positron emission tomographic (pet) images has been approved by regulatory authorities for clinical use several immunoassays have been developed to measure β-amyloid (aβ) 42 in cerebrospinal fluid (csf) the agreement between csf aβ42 measures from different immunoassays and visual pet readings may influence the use of csf biomarkers and/or amyloid pet assessment in clinical practice and trials objective to determine the concordance between csf aβ42 levels measured using 5 different immunoassays and visual amyloid pet analysis design, setting, and participants the study included 262 patients with mild cognitive impairment or subjective cognitive decline from the swedish biofinder (biomarkers for identifying neurodegenerative disorders early and reliably) cohort (recruited from september 1, 2010, through december 31, 2014) who had undergon\n"
     ]
    }
   ],
   "source": [
    "# Concatenating all sentences into one text.\n",
    "one_text = \" \".join(df['sentence'])\n",
    "print(one_text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 32281),\n",
       " ('of', 26693),\n",
       " ('and', 26293),\n",
       " ('in', 18512),\n",
       " ('to', 14256),\n",
       " ('a', 10400),\n",
       " ('with', 8458),\n",
       " ('for', 7671),\n",
       " ('were', 5245),\n",
       " ('was', 4824),\n",
       " ('is', 4493),\n",
       " ('on', 4078),\n",
       " ('patients', 3976),\n",
       " ('that', 3856),\n",
       " ('by', 3522),\n",
       " ('as', 3272),\n",
       " ('from', 3194),\n",
       " ('this', 3041),\n",
       " ('at', 2887),\n",
       " ('we', 2850)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we find the most common words\n",
    "top_words = Counter(one_text.split()).most_common()\n",
    "top_words[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(p', '0', '1', '2', '3', '4', '5', '6', '=', 'a', 'after', 'all', 'also', 'among', 'an', 'analysis', 'and', 'are', 'as', 'associated', 'at', 'be', 'been', 'between', 'both', 'but', 'by', 'can', 'cancer', 'change', 'climate', 'clinical', 'compared', 'data', 'different', 'during', 'effects', 'energy', 'for', 'from', 'global', 'group', 'groups', 'had', 'has', 'have', 'health', 'higher', 'in', 'increased', 'is', 'it', 'life', 'may', 'model', 'months', 'more', 'mortality', 'most', 'no', 'not', 'of', 'on', 'or', 'other', 'our', 'over', 'p', 'patients', 'quality', 'randomized', 'results', 'risk', 'significant', 'significantly', 'study', 'survival', 'than', 'that', 'the', 'their', 'there', 'these', 'this', 'time', 'to', 'treatment', 'trial', 'two', 'use', 'used', 'using', 'was', 'we', 'were', 'which', 'who', 'with', 'women', 'years']\n"
     ]
    }
   ],
   "source": [
    "# Printing the top 100 most common words \n",
    "print(sorted([i[0].lower() for i in top_words[:100]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we also use the english stop words from the nltk library\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we combine stop words and most common used words into a list in order to later remove them from our data frame.\n",
    "most_common = top_words[:100]\n",
    "words_to_exclude = most_common+stop\n",
    "words_to_exclude = list(dict.fromkeys(words_to_exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we remove them and form a new column which contains the \"clean\" text\n",
    "df['sentence_clean'] = df['sentence'].apply(lambda x: ' '.join([word for word in x.split() if word not in (words_to_exclude)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEITHER</td>\n",
       "      <td>concordance different amyloid immunoassays vis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NEITHER</td>\n",
       "      <td>importance visual assessment amyloid positron ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NEITHER</td>\n",
       "      <td>several immunoassays developed measure β-amylo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NEITHER</td>\n",
       "      <td>agreement csf aβ42 measures different immunoas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NEITHER</td>\n",
       "      <td>objective determine concordance csf aβ42 level...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31999</th>\n",
       "      <td>EVIDENCE</td>\n",
       "      <td>statistically significant difference conjuncti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32000</th>\n",
       "      <td>NEITHER</td>\n",
       "      <td>latanoprost 0 005% daily reduced iop effective...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32001</th>\n",
       "      <td>CLAIM</td>\n",
       "      <td>latanoprost statistically clinically significa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32002</th>\n",
       "      <td>CLAIM</td>\n",
       "      <td>difference hyperemia two regimens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32003</th>\n",
       "      <td>CLAIM</td>\n",
       "      <td>concentrations latanoprost reduced iop least w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32004 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          label                                     sentence_clean\n",
       "0       NEITHER  concordance different amyloid immunoassays vis...\n",
       "1       NEITHER  importance visual assessment amyloid positron ...\n",
       "2       NEITHER  several immunoassays developed measure β-amylo...\n",
       "3       NEITHER  agreement csf aβ42 measures different immunoas...\n",
       "4       NEITHER  objective determine concordance csf aβ42 level...\n",
       "...         ...                                                ...\n",
       "31999  EVIDENCE  statistically significant difference conjuncti...\n",
       "32000   NEITHER  latanoprost 0 005% daily reduced iop effective...\n",
       "32001     CLAIM  latanoprost statistically clinically significa...\n",
       "32002     CLAIM                  difference hyperemia two regimens\n",
       "32003     CLAIM  concentrations latanoprost reduced iop least w...\n",
       "\n",
       "[32004 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we remove the older column which contained raw text\n",
    "df = df.drop(['sentence'] ,axis =1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We split our data frame into a train-validation and a test data frame.\n",
    "train_valid, test = train_test_split(df, test_size = 0.2 , random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24522    EVIDENCE\n",
       "14640     NEITHER\n",
       "10299    EVIDENCE\n",
       "24540     NEITHER\n",
       "22577     NEITHER\n",
       "           ...   \n",
       "3274      NEITHER\n",
       "1808      NEITHER\n",
       "21524       CLAIM\n",
       "20509     NEITHER\n",
       "17967    EVIDENCE\n",
       "Name: label, Length: 6401, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#keeping actual labels of test dataset\n",
    "y_true_test = test['label']\n",
    "y_true_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4814</th>\n",
       "      <td>NEITHER</td>\n",
       "      <td>nonalcoholic fatty liver disease (nafld) encom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11976</th>\n",
       "      <td>NEITHER</td>\n",
       "      <td>1-year postoperatively, first woman reported c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4416</th>\n",
       "      <td>NEITHER</td>\n",
       "      <td>case zikv infection, role osteoblasts zikv pat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17730</th>\n",
       "      <td>NEITHER</td>\n",
       "      <td>study investigates association hap cooking fue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25163</th>\n",
       "      <td>EVIDENCE</td>\n",
       "      <td>statistically significant qol difference treat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29802</th>\n",
       "      <td>NEITHER</td>\n",
       "      <td>randomized controlled trial conducted patients...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>NEITHER</td>\n",
       "      <td>real-time assessment health-care requirements ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>NEITHER</td>\n",
       "      <td>large discrepancies summer climate change euro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>NEITHER</td>\n",
       "      <td>distribution near normal scale show ceiling ef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23654</th>\n",
       "      <td>EVIDENCE</td>\n",
       "      <td>final multivariate model response selected dfi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25603 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          label                                     sentence_clean\n",
       "4814    NEITHER  nonalcoholic fatty liver disease (nafld) encom...\n",
       "11976   NEITHER  1-year postoperatively, first woman reported c...\n",
       "4416    NEITHER  case zikv infection, role osteoblasts zikv pat...\n",
       "17730   NEITHER  study investigates association hap cooking fue...\n",
       "25163  EVIDENCE  statistically significant qol difference treat...\n",
       "...         ...                                                ...\n",
       "29802   NEITHER  randomized controlled trial conducted patients...\n",
       "5390    NEITHER  real-time assessment health-care requirements ...\n",
       "860     NEITHER  large discrepancies summer climate change euro...\n",
       "15795   NEITHER  distribution near normal scale show ceiling ef...\n",
       "23654  EVIDENCE  final multivariate model response selected dfi...\n",
       "\n",
       "[25603 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we split again our train-validation data frame into 2 separate data frames (train & validation)\n",
    "train, valid = train_test_split(train_valid, test_size = 0.2 , random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "482       NEITHER\n",
       "17159       CLAIM\n",
       "5773      NEITHER\n",
       "31434    EVIDENCE\n",
       "15817     NEITHER\n",
       "           ...   \n",
       "12109     NEITHER\n",
       "29067     NEITHER\n",
       "28590    EVIDENCE\n",
       "3071      NEITHER\n",
       "24070     NEITHER\n",
       "Name: label, Length: 20482, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#keeping actual labels of train dataset\n",
    "y_true_train = train['label']\n",
    "y_true_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21239     NEITHER\n",
       "25283     NEITHER\n",
       "26157     NEITHER\n",
       "20931     NEITHER\n",
       "20767    EVIDENCE\n",
       "           ...   \n",
       "31907     NEITHER\n",
       "24353       CLAIM\n",
       "2198      NEITHER\n",
       "17015     NEITHER\n",
       "27883     NEITHER\n",
       "Name: label, Length: 5121, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#keeping actual labels of valid dataset\n",
    "y_true_valid = valid['label']\n",
    "y_true_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bandi\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1783: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item_labels[indexer[info_axis]]] = value\n"
     ]
    }
   ],
   "source": [
    "#we fix the format of the label column in order to later match to the fasttext's required input format.\n",
    "train.iloc[:, 0] = train.iloc[:, 0].apply(lambda x: '__label__' + x)\n",
    "valid.iloc[:, 0] = valid.iloc[:, 0].apply(lambda x: '__label__' + x)\n",
    "test.iloc[:, 0] = test.iloc[:, 0].apply(lambda x: '__label__' + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21239</th>\n",
       "      <td>__label__NEITHER</td>\n",
       "      <td>wind velocity fields measured four cross-secti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25283</th>\n",
       "      <td>__label__NEITHER</td>\n",
       "      <td>sedentary (engaging &lt;60 min recreational activ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26157</th>\n",
       "      <td>__label__NEITHER</td>\n",
       "      <td>response rate 88 4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20931</th>\n",
       "      <td>__label__NEITHER</td>\n",
       "      <td>increases frequency, duration, and/or severity...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20767</th>\n",
       "      <td>__label__EVIDENCE</td>\n",
       "      <td>show positive trends oc 474 streams, lakes, ri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31907</th>\n",
       "      <td>__label__NEITHER</td>\n",
       "      <td>randomized double-masked crossover study compa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24353</th>\n",
       "      <td>__label__CLAIM</td>\n",
       "      <td>patients cancer, high-fat diet may possibly su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>__label__NEITHER</td>\n",
       "      <td>pro-c3 collagen neo-epitope putative direct ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17015</th>\n",
       "      <td>__label__NEITHER</td>\n",
       "      <td>finding important implications improving mater...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27883</th>\n",
       "      <td>__label__NEITHER</td>\n",
       "      <td>hypothesised 2-weekly administration docetaxel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5121 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   label                                     sentence_clean\n",
       "21239   __label__NEITHER  wind velocity fields measured four cross-secti...\n",
       "25283   __label__NEITHER  sedentary (engaging <60 min recreational activ...\n",
       "26157   __label__NEITHER                                response rate 88 4%\n",
       "20931   __label__NEITHER  increases frequency, duration, and/or severity...\n",
       "20767  __label__EVIDENCE  show positive trends oc 474 streams, lakes, ri...\n",
       "...                  ...                                                ...\n",
       "31907   __label__NEITHER  randomized double-masked crossover study compa...\n",
       "24353     __label__CLAIM  patients cancer, high-fat diet may possibly su...\n",
       "2198    __label__NEITHER  pro-c3 collagen neo-epitope putative direct ma...\n",
       "17015   __label__NEITHER  finding important implications improving mater...\n",
       "27883   __label__NEITHER  hypothesised 2-weekly administration docetaxel...\n",
       "\n",
       "[5121 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-cb2e4ad954e8>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[\"fasttext\"] = train[\"sentence_clean\"] + ' ' + train[\"label\"]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fasttext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>flexible polymers poly dimethyl siloxane (pdms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17159</th>\n",
       "      <td>efforts tackle pedestrian safety focus five re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5773</th>\n",
       "      <td>ventricular tachycardia also inducible remaini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31434</th>\n",
       "      <td>comparison mean diurnal measurements latanopro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15817</th>\n",
       "      <td>response, integrated care programmes appearing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12109</th>\n",
       "      <td>retrospective case analysis __label__NEITHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29067</th>\n",
       "      <td>primary efficacy endpoint diurnal iop (average...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28590</th>\n",
       "      <td>overall, eyes slt travoprost groups achieved s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3071</th>\n",
       "      <td>high, anisotropic, substrate-independent mobil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24070</th>\n",
       "      <td>double-blind, randomised, phase 3 trial undert...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20482 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                fasttext\n",
       "482    flexible polymers poly dimethyl siloxane (pdms...\n",
       "17159  efforts tackle pedestrian safety focus five re...\n",
       "5773   ventricular tachycardia also inducible remaini...\n",
       "31434  comparison mean diurnal measurements latanopro...\n",
       "15817  response, integrated care programmes appearing...\n",
       "...                                                  ...\n",
       "12109       retrospective case analysis __label__NEITHER\n",
       "29067  primary efficacy endpoint diurnal iop (average...\n",
       "28590  overall, eyes slt travoprost groups achieved s...\n",
       "3071   high, anisotropic, substrate-independent mobil...\n",
       "24070  double-blind, randomised, phase 3 trial undert...\n",
       "\n",
       "[20482 rows x 1 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for the train dataset\n",
    "#we combine the 2 columns into a new column which is required for the fasttext input format\n",
    "train[\"fasttext\"] = train[\"sentence_clean\"] + ' ' + train[\"label\"]\n",
    "#we drop the 2 older columns\n",
    "train = train.drop(['sentence_clean'],axis =1)\n",
    "train = train.drop(['label'],axis =1)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-30-bcb033600201>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  valid[\"fasttext\"] = valid[\"sentence_clean\"] + ' ' + valid[\"label\"]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fasttext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21239</th>\n",
       "      <td>wind velocity fields measured four cross-secti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25283</th>\n",
       "      <td>sedentary (engaging &lt;60 min recreational activ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26157</th>\n",
       "      <td>response rate 88 4% __label__NEITHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20931</th>\n",
       "      <td>increases frequency, duration, and/or severity...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20767</th>\n",
       "      <td>show positive trends oc 474 streams, lakes, ri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31907</th>\n",
       "      <td>randomized double-masked crossover study compa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24353</th>\n",
       "      <td>patients cancer, high-fat diet may possibly su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>pro-c3 collagen neo-epitope putative direct ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17015</th>\n",
       "      <td>finding important implications improving mater...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27883</th>\n",
       "      <td>hypothesised 2-weekly administration docetaxel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5121 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                fasttext\n",
       "21239  wind velocity fields measured four cross-secti...\n",
       "25283  sedentary (engaging <60 min recreational activ...\n",
       "26157               response rate 88 4% __label__NEITHER\n",
       "20931  increases frequency, duration, and/or severity...\n",
       "20767  show positive trends oc 474 streams, lakes, ri...\n",
       "...                                                  ...\n",
       "31907  randomized double-masked crossover study compa...\n",
       "24353  patients cancer, high-fat diet may possibly su...\n",
       "2198   pro-c3 collagen neo-epitope putative direct ma...\n",
       "17015  finding important implications improving mater...\n",
       "27883  hypothesised 2-weekly administration docetaxel...\n",
       "\n",
       "[5121 rows x 1 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for the validation dataset\n",
    "#we combine the 2 columns into a new column which is required for the fasttext input format\n",
    "valid[\"fasttext\"] = valid[\"sentence_clean\"] + ' ' + valid[\"label\"]\n",
    "#we drop the 2 older columns\n",
    "valid = valid.drop(['sentence_clean'],axis =1)\n",
    "valid = valid.drop(['label'],axis =1)\n",
    "valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-31-60bede269d5c>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[\"fasttext\"] = test[\"sentence_clean\"] + ' ' + test[\"label\"]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fasttext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24522</th>\n",
       "      <td>results showed overall significant improvement...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14640</th>\n",
       "      <td>item response analysis showed excellent sensit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10299</th>\n",
       "      <td>find two key regions surface responsible devel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24540</th>\n",
       "      <td>health-related quality life (hrqol; explorator...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22577</th>\n",
       "      <td>summarised current knowledge regarding risk fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3274</th>\n",
       "      <td>use radiative kernels understand influence rap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808</th>\n",
       "      <td>compared experts, iam simulations projected gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21524</th>\n",
       "      <td>based contributions special issue, several rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20509</th>\n",
       "      <td>abstract: study examines state local practice ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17967</th>\n",
       "      <td>road traffic injury rates increased 40 7 per 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6401 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                fasttext\n",
       "24522  results showed overall significant improvement...\n",
       "14640  item response analysis showed excellent sensit...\n",
       "10299  find two key regions surface responsible devel...\n",
       "24540  health-related quality life (hrqol; explorator...\n",
       "22577  summarised current knowledge regarding risk fa...\n",
       "...                                                  ...\n",
       "3274   use radiative kernels understand influence rap...\n",
       "1808   compared experts, iam simulations projected gr...\n",
       "21524  based contributions special issue, several rec...\n",
       "20509  abstract: study examines state local practice ...\n",
       "17967  road traffic injury rates increased 40 7 per 1...\n",
       "\n",
       "[6401 rows x 1 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for the test dataset\n",
    "#we combine the 2 columns into a new column which is required for the fasttext input format\n",
    "test[\"fasttext\"] = test[\"sentence_clean\"] + ' ' + test[\"label\"]\n",
    "#we drop the 2 older columns\n",
    "test = test.drop(['sentence_clean'],axis =1)\n",
    "test = test.drop(['label'],axis =1)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we produce a .txt file from the test dataset which will be later used as test input in our fasttext model\n",
    "test.to_csv('test.txt', index = False, header = False, quotechar = \" \", escapechar = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we produce a .txt file from the train dataset which will be later used as train input in our fasttext model\n",
    "train.to_csv('train.txt', index = False, header = False, quotechar = \" \", escapechar = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we produce a .txt file from the validation dataset which will be later used as validation input in our fasttext model\n",
    "valid.to_csv('valid.txt', index = False, header = False, quotechar = \" \", escapechar = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "### WE USED DIFFERENT PARAMETERS AND TRIED MANY OPTIONS WITH THE SUPERVISED TRAINING MODEL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We train our model\n",
    "model = fasttext.train_supervised(input=\"train.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21239</th>\n",
       "      <td>wind velocity fields measured four cross-secti...</td>\n",
       "      <td>NEITHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25283</th>\n",
       "      <td>sedentary (engaging &lt;60 min recreational activ...</td>\n",
       "      <td>NEITHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26157</th>\n",
       "      <td>response rate 88 4%</td>\n",
       "      <td>NEITHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20931</th>\n",
       "      <td>increases frequency, duration, and/or severity...</td>\n",
       "      <td>NEITHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20767</th>\n",
       "      <td>show positive trends oc 474 streams, lakes, ri...</td>\n",
       "      <td>EVIDENCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31907</th>\n",
       "      <td>randomized double-masked crossover study compa...</td>\n",
       "      <td>NEITHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24353</th>\n",
       "      <td>patients cancer, high-fat diet may possibly su...</td>\n",
       "      <td>CLAIM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>pro-c3 collagen neo-epitope putative direct ma...</td>\n",
       "      <td>NEITHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17015</th>\n",
       "      <td>finding important implications improving mater...</td>\n",
       "      <td>NEITHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27883</th>\n",
       "      <td>hypothesised 2-weekly administration docetaxel...</td>\n",
       "      <td>NEITHER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5121 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence     label\n",
       "21239  wind velocity fields measured four cross-secti...   NEITHER\n",
       "25283  sedentary (engaging <60 min recreational activ...   NEITHER\n",
       "26157                               response rate 88 4%    NEITHER\n",
       "20931  increases frequency, duration, and/or severity...   NEITHER\n",
       "20767  show positive trends oc 474 streams, lakes, ri...  EVIDENCE\n",
       "...                                                  ...       ...\n",
       "31907  randomized double-masked crossover study compa...   NEITHER\n",
       "24353  patients cancer, high-fat diet may possibly su...     CLAIM\n",
       "2198   pro-c3 collagen neo-epitope putative direct ma...   NEITHER\n",
       "17015  finding important implications improving mater...   NEITHER\n",
       "27883  hypothesised 2-weekly administration docetaxel...   NEITHER\n",
       "\n",
       "[5121 rows x 2 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reforming the validation dataset without the prefix\n",
    "valid[['sentence','label']] = valid[\"fasttext\"].str.split(\"__label__\",expand=True)\n",
    "valid = valid.drop(['fasttext'],axis =1)\n",
    "valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24522</th>\n",
       "      <td>results showed overall significant improvement...</td>\n",
       "      <td>EVIDENCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14640</th>\n",
       "      <td>item response analysis showed excellent sensit...</td>\n",
       "      <td>NEITHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10299</th>\n",
       "      <td>find two key regions surface responsible devel...</td>\n",
       "      <td>EVIDENCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24540</th>\n",
       "      <td>health-related quality life (hrqol; explorator...</td>\n",
       "      <td>NEITHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22577</th>\n",
       "      <td>summarised current knowledge regarding risk fa...</td>\n",
       "      <td>NEITHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3274</th>\n",
       "      <td>use radiative kernels understand influence rap...</td>\n",
       "      <td>NEITHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808</th>\n",
       "      <td>compared experts, iam simulations projected gr...</td>\n",
       "      <td>NEITHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21524</th>\n",
       "      <td>based contributions special issue, several rec...</td>\n",
       "      <td>CLAIM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20509</th>\n",
       "      <td>abstract: study examines state local practice ...</td>\n",
       "      <td>NEITHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17967</th>\n",
       "      <td>road traffic injury rates increased 40 7 per 1...</td>\n",
       "      <td>EVIDENCE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6401 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence     label\n",
       "24522  results showed overall significant improvement...  EVIDENCE\n",
       "14640  item response analysis showed excellent sensit...   NEITHER\n",
       "10299  find two key regions surface responsible devel...  EVIDENCE\n",
       "24540  health-related quality life (hrqol; explorator...   NEITHER\n",
       "22577  summarised current knowledge regarding risk fa...   NEITHER\n",
       "...                                                  ...       ...\n",
       "3274   use radiative kernels understand influence rap...   NEITHER\n",
       "1808   compared experts, iam simulations projected gr...   NEITHER\n",
       "21524  based contributions special issue, several rec...     CLAIM\n",
       "20509  abstract: study examines state local practice ...   NEITHER\n",
       "17967  road traffic injury rates increased 40 7 per 1...  EVIDENCE\n",
       "\n",
       "[6401 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reforming the test dataset without the prefix\n",
    "test[['sentence','label']] = test[\"fasttext\"].str.split(\"__label__\",expand=True)\n",
    "test = test.drop(['fasttext'],axis =1)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21239    __label__NEITHER\n",
       "25283    __label__NEITHER\n",
       "26157    __label__NEITHER\n",
       "20931    __label__NEITHER\n",
       "20767    __label__NEITHER\n",
       "               ...       \n",
       "31907    __label__NEITHER\n",
       "24353    __label__NEITHER\n",
       "2198     __label__NEITHER\n",
       "17015    __label__NEITHER\n",
       "27883      __label__CLAIM\n",
       "Name: sentence, Length: 5121, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#forming the validation dataset properly to be used as input\n",
    "valid_sentences = valid[\"sentence\"].apply(lambda s: \" \".join(s.split()))\n",
    "valid_sentences = valid_sentences.apply(lambda s: model.predict(s)[0][0])\n",
    "valid_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21239    NEITHER\n",
       "25283    NEITHER\n",
       "26157    NEITHER\n",
       "20931    NEITHER\n",
       "20767    NEITHER\n",
       "          ...   \n",
       "31907    NEITHER\n",
       "24353    NEITHER\n",
       "2198     NEITHER\n",
       "17015    NEITHER\n",
       "27883      CLAIM\n",
       "Name: sentence, Length: 5121, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing the prefix from the predicted outcome\n",
    "y_pred_valid = valid_sentences.str.replace('__label__','')\n",
    "y_pred_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24522    __label__EVIDENCE\n",
       "14640     __label__NEITHER\n",
       "10299     __label__NEITHER\n",
       "24540     __label__NEITHER\n",
       "22577     __label__NEITHER\n",
       "               ...        \n",
       "3274      __label__NEITHER\n",
       "1808      __label__NEITHER\n",
       "21524     __label__NEITHER\n",
       "20509     __label__NEITHER\n",
       "17967    __label__EVIDENCE\n",
       "Name: sentence, Length: 6401, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##forming the test dataset properly to be used as input\n",
    "test_sentences = test[\"sentence\"].apply(lambda s: \" \".join(s.split()))\n",
    "test_sentences = test_sentences.apply(lambda s: model.predict(s)[0][0])\n",
    "test_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24522    EVIDENCE\n",
       "14640     NEITHER\n",
       "10299     NEITHER\n",
       "24540     NEITHER\n",
       "22577     NEITHER\n",
       "           ...   \n",
       "3274      NEITHER\n",
       "1808      NEITHER\n",
       "21524     NEITHER\n",
       "20509     NEITHER\n",
       "17967    EVIDENCE\n",
       "Name: sentence, Length: 6401, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing the prefix from the predicted outcome of test dataset\n",
    "y_pred_test = test_sentences.str.replace('__label__','')\n",
    "y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a list with labels\n",
    "target_names = ['CLAIM', 'EVIDENCE', 'NEITHER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21239     NEITHER\n",
       "25283     NEITHER\n",
       "26157     NEITHER\n",
       "20931     NEITHER\n",
       "20767    EVIDENCE\n",
       "           ...   \n",
       "31907     NEITHER\n",
       "24353       CLAIM\n",
       "2198      NEITHER\n",
       "17015     NEITHER\n",
       "27883     NEITHER\n",
       "Name: label, Length: 5121, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing the prefix from the predicted outcome\n",
    "y_true_valid = y_true_valid.str.replace('__label__','')\n",
    "y_true_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24522    EVIDENCE\n",
       "14640     NEITHER\n",
       "10299    EVIDENCE\n",
       "24540     NEITHER\n",
       "22577     NEITHER\n",
       "           ...   \n",
       "3274      NEITHER\n",
       "1808      NEITHER\n",
       "21524       CLAIM\n",
       "20509     NEITHER\n",
       "17967    EVIDENCE\n",
       "Name: label, Length: 6401, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true_test = y_true_test.str.replace('__label__','')\n",
    "y_true_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       CLAIM       0.53      0.31      0.39       521\n",
      "    EVIDENCE       0.64      0.52      0.57      1009\n",
      "     NEITHER       0.82      0.91      0.86      3591\n",
      "\n",
      "    accuracy                           0.77      5121\n",
      "   macro avg       0.66      0.58      0.61      5121\n",
      "weighted avg       0.75      0.77      0.76      5121\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#FOR VALIDATION DATASET\n",
    "print('validation dataset')\n",
    "print(classification_report(y_true_valid, y_pred_valid, labels=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#By default, fastText sees each training example only five times during training, which is pretty small, \n",
    "#given that our training set only have 20.5k training examples.\n",
    "#The number of times each examples is seen (also known as the number of epochs), can be increased using the -epoch option:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We train our model again implemeting hyper parameter tunning (epochs)\n",
    "model_2 = fasttext.train_supervised(input=\"train.txt\", epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       CLAIM       0.47      0.37      0.41       521\n",
      "    EVIDENCE       0.60      0.55      0.57      1009\n",
      "     NEITHER       0.83      0.87      0.85      3591\n",
      "\n",
      "    accuracy                           0.76      5121\n",
      "   macro avg       0.63      0.60      0.61      5121\n",
      "weighted avg       0.75      0.76      0.75      5121\n",
      "\n"
     ]
    }
   ],
   "source": [
    "valid_sentences = valid[\"sentence\"].apply(lambda s: \" \".join(s.split()))\n",
    "valid_sentences = valid_sentences.apply(lambda s: model_2.predict(s)[0][0])\n",
    "y_pred_valid = valid_sentences.str.replace('__label__','')\n",
    "#FOR VALIDATION DATASET\n",
    "print('validation dataset')\n",
    "print(classification_report(y_true_valid, y_pred_valid, labels=target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#epoch's increment does not seem to make our model better (f1 score is not affected that much neither accuracy)\n",
    "#thus we will keep epoch = 5 (by default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Another way to change the learning speed of our model is to increase (or decrease) the learning rate of the algorithm.\n",
    "#This corresponds to how much the model changes after processing each example. \n",
    "#A learning rate of 0 would mean that the model does not change at all, and thus, does not learn anything. \n",
    "#Good values of the learning rate are in the range 0.1 - 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       CLAIM       0.45      0.38      0.41       521\n",
      "    EVIDENCE       0.60      0.56      0.58      1009\n",
      "     NEITHER       0.84      0.87      0.85      3591\n",
      "\n",
      "    accuracy                           0.76      5121\n",
      "   macro avg       0.63      0.60      0.61      5121\n",
      "weighted avg       0.75      0.76      0.75      5121\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#We train our model again implemeting hyper parameter tunning (learning rate)\n",
    "model_3 = fasttext.train_supervised(input=\"train.txt\", lr=0.5)\n",
    "valid_sentences = valid[\"sentence\"].apply(lambda s: \" \".join(s.split()))\n",
    "valid_sentences = valid_sentences.apply(lambda s: model_3.predict(s)[0][0])\n",
    "y_pred_valid = valid_sentences.str.replace('__label__','')\n",
    "#FOR VALIDATION DATASET\n",
    "print('validation dataset')\n",
    "print(classification_report(y_true_valid, y_pred_valid, labels=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning's rate (lr) increment does not seem to make our model better \n",
    "#thus we will keep learning rate = 0.1 (by default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally, we can improve the performance of a model by using word bigrams, instead of just unigrams. \n",
    "#This is especially important for classification problems where word order is important, such as sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       CLAIM       0.59      0.27      0.37       521\n",
      "    EVIDENCE       0.67      0.52      0.58      1009\n",
      "     NEITHER       0.81      0.93      0.87      3591\n",
      "\n",
      "    accuracy                           0.78      5121\n",
      "   macro avg       0.69      0.57      0.61      5121\n",
      "weighted avg       0.76      0.78      0.76      5121\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#We train our model again implemeting hyper parameter tunning (wordNgrams)\n",
    "model_4 = fasttext.train_supervised(input=\"train.txt\",wordNgrams=2)\n",
    "valid_sentences = valid[\"sentence\"].apply(lambda s: \" \".join(s.split()))\n",
    "valid_sentences = valid_sentences.apply(lambda s: model_4.predict(s)[0][0])\n",
    "y_pred_valid = valid_sentences.str.replace('__label__','')\n",
    "#FOR VALIDATION DATASET\n",
    "print('validation dataset')\n",
    "print(classification_report(y_true_valid, y_pred_valid, labels=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wordNgrams increment decreases f1 score as accuracy remains the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       CLAIM       0.46      0.36      0.41       521\n",
      "    EVIDENCE       0.59      0.56      0.58      1009\n",
      "     NEITHER       0.84      0.87      0.85      3591\n",
      "\n",
      "    accuracy                           0.76      5121\n",
      "   macro avg       0.63      0.60      0.61      5121\n",
      "weighted avg       0.75      0.76      0.75      5121\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#We train our model again implemeting hyper parameter tunning\n",
    "model_5 = fasttext.train_supervised(input=\"train.txt\", loss='hs', lr=0.7, epoch=18,wordNgrams=2)\n",
    "valid_sentences = valid[\"sentence\"].apply(lambda s: \" \".join(s.split()))\n",
    "valid_sentences = valid_sentences.apply(lambda s: model_5.predict(s)[0][0])\n",
    "y_pred_valid = valid_sentences.str.replace('__label__','')\n",
    "#FOR VALIDATION DATASET\n",
    "print('validation dataset')\n",
    "print(classification_report(y_true_valid, y_pred_valid, labels=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will use model_5 in our test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       CLAIM       0.52      0.40      0.45       669\n",
      "    EVIDENCE       0.59      0.59      0.59      1209\n",
      "     NEITHER       0.85      0.88      0.86      4523\n",
      "\n",
      "    accuracy                           0.77      6401\n",
      "   macro avg       0.65      0.62      0.63      6401\n",
      "weighted avg       0.76      0.77      0.77      6401\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_sentences = test[\"sentence\"].apply(lambda s: \" \".join(s.split()))\n",
    "test_sentences = test_sentences.apply(lambda s: model_5.predict(s)[0][0])\n",
    "y_pred_test = test_sentences.str.replace('__label__','')\n",
    "#FOR test DATASET\n",
    "print('test dataset')\n",
    "print(classification_report(y_true_test, y_pred_test, labels=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving our best model\n",
    "model_5.save_model(\"fasttext_arguments_final_model.bin\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
